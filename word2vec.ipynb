{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Models for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Word2Vec model is a simple word embedding neural network, developed by Mikolov et al. (2013).\n",
    "####  *Such continuous word embedding representations have have been proven to be able to carry semantic meanings and are useful in various NLP tasks.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have attempted to implement three language models described in *Le & Mikolov (2014)*'s paper ** *Distributed Representations of Sentences and Documents* **.\n",
    "\n",
    "The implementations don't make use of any NLP libraries and consist of the simplest form of the algorithm with little optimization.\n",
    "The aim of this notebook is simply to gain:\n",
    "* understanding of the **language models' algorithm**\n",
    "* intuition on **word embedding representations**\n",
    "* understanding of inner workings of **neural networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLP, popular fixed-length features used in language models are **bag-of-words**.\n",
    "\n",
    "However bag-of-words features have two major weaknesses: \n",
    "- they lose the **ordering** of the words.\n",
    "- they also ignore **semantics** of the words. \n",
    "\n",
    "In the paper by **Le & Mikolov (2014)**, they propose a distributed representation of sentences and documents, which they call ** *Paragraph Vector* **. \n",
    "\n",
    "The model assumes the ** *Distributional Hypothesis* ** that words are characterized by other words in their vicinity. This idea is used to estimate the probability of two words occurring near each other.\n",
    "\n",
    "*Paragraph Vector* is an **unsupervised algorithm** that learns fixed-length feature representations from **variable-length pieces of texts**, such as sentences and paragraphs. The algorithm represents each word and sentence by a dense vector which is trained to predict words in the document. Its construction gives the algorithm the potential to overcome the **weaknesses** of bag-of- words models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/3.png\"  width=\"500\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirical results, in the paper, show that **Paragraph Vectors outperform bag-of-words models**, as well as, other techniques for text representations. For example, **word weighting functions** (which requires task-specific tuning) and **parse trees**. The authors were able to achieve new **state-of-the-art** results on several **text classification** and **sentiment analysis** tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is made possible because words with **similar meaning** are mapped to a **similar position** in the **vector space**. The difference between word vectors also carry meaning. For example, the word vectors can be used to answer analogy questions using simple vector algebra: “King” - “man” + “woman” = “Queen”.\n",
    "Theses properties of word vectors are useful in many NLP task, such as **language modeling and understanding** and **machine translation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Word Context Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this  first language model, we will look at the simplest form of the *Continuous Bag-Of-Word Model (CBOW)* introduced in *Mikolov et al. (2013a)*. This model has just **one word** as the context to predict the next target word in the sentence. This context vector is fed into a **neural network** with a **single hidden layer** that is fully connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/1neural-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input vector is a **one-hot encoded vector**. Each word is mapped into its own **unique vector of features**, represented by a column in the matrix $W_I$. There is also another weight matrix, $W_O$ connecting the hidden layer to the output layer.\n",
    "\n",
    "Given a **context word** and these **weight matrices**, we can compute a **score** for each word in the vocabulary. This is essentially a **multiclass classification** where we have as many labels as our vocabulary size $V$. **Softmax regression**, a log-linear classification model, is used to compute the **posterior probability $P(W_O|W_I)$:**\n",
    "\n",
    "$$ P(W_O|W_I) = y_i = \\frac{exp(W_I \\cdot W'^T_O)}{\\sum^V_{j=1} exp(W_I \\cdot W'^T_j)} $$\n",
    "\n",
    "In the paper, **hierarchical softmax** is used for faster training, but for simpliticy I will just use a regular softmax regression as the multiclass classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous embeddings of the words represent **points in a vector space**. What the Word2Vec model is trying to do is assign each word a **meaningful point** in that space that represent its **semantic** in **relation** to the other words. The words are first **initialized to a random location** in that space, the model will then try  to learn better vector positions. Similar words will be **pushed together**, while different ones will be **pulled away.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the hidden-to-output layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model learns by maximzing the posterior probability. For **numerical stability**, we will instead **minimize the log loss function**: \n",
    "\n",
    "$$E = -\\log P(W_O|W_I)$$\n",
    "\n",
    "$$E = -\\log \\frac{exp(W_I \\cdot W'^T_O)}{\\sum^V_{j=1} exp(W_I \\cdot W'^T_j)} =-\\log \\frac{exp(u)}{\\sum^V_{j=1} exp(u_j)} $$\n",
    "\n",
    "$$E = -u + \\log \\sum^V_{j=1} exp(u_j)$$\n",
    "\n",
    "The update equation of the weights between **hidden and output layers**:\n",
    "\n",
    "$$\\dfrac{\\partial E}{\\partial u} = -t_j + \\frac{exp(u)}{\\sum^V_{j=1} exp(u_j)}$$\n",
    "$$ \\dfrac{\\partial E}{\\partial u} = P(W_O|W_I) - t_j = e_j$$\n",
    "\n",
    "Where $t_j = 1$ if the **output word is the actual target**, otherwise $t_j = 0$. This derivative is also the **prediction error of the output layer**, $e_j$.\n",
    "\n",
    "The **gradient** on the hidden-to-output weights is:\n",
    "$$ \\dfrac{\\partial E}{\\partial W_O} = \\dfrac{\\partial E}{\\partial u_j} \\cdot \\dfrac{\\partial u_j}{\\partial W_O} = e_j \\cdot h_i$$\n",
    "\n",
    "Where $h_i$ is a copy of the vector corresponding to the **input word**. \n",
    "\n",
    "To **update the  output weights**, $W_O$, for the hidden-to-output layer, **stochastic gradient descent** is used with a learning rate $\\alpha$: \n",
    "\n",
    "$${W_{O}}^{T (new)}_j = {W_{O}}^{T (old)}_j - \\alpha \\cdot e_j \\cdot h_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the input-to-hidden layer weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **prediction errors** need to be **backpropagated** to the input-to-hidden weights. \n",
    "\n",
    "The derivative of $E$ on the output of the hidden layer is:\n",
    "\n",
    "$$ \\dfrac{\\partial E}{\\partial h_i} = \\sum^V_{j=1} \\dfrac{\\partial E}{\\partial u_j} \\cdot \\dfrac{\\partial u_j}{\\partial h_i} = \\sum^V_{j=1} e_j \\cdot W_O = EH$$\n",
    "\n",
    "EH is the **sum of the hidden-to-output vectors** for each word in the vocabulary **weighted** by their **prediction error**.\n",
    "\n",
    "The **gradient** on the input weights is:\n",
    "\n",
    "$$ \\dfrac{\\partial E}{\\partial W_I} = \\dfrac{\\partial E}{\\partial h_i} \\cdot \\dfrac{\\partial h_i}{\\partial W_I} = EH_i \\cdot x$$\n",
    "\n",
    "Where $x$ is one-hot encoded vector.\n",
    "\n",
    "To **update the  intput weights** for the input-to-hidden layer, we make use again of **stochastic gradient descent**, with a learning rate $\\alpha$: \n",
    "\n",
    "$${W_{I}}^{T (new)}_j = {W_{I}}^{T (old)}_j - \\alpha \\cdot EH $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have good idea how the model works, we'd like to see it in action. To keep this notebook **concise and readable** I have kept the code in separate files located in the same directory of this notebook.\n",
    "\n",
    "This **first model** can be found in file * \"Word2Vec_1WordContext.py\" *\n",
    "\n",
    "Let's test this model with a *tiny* toy dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = ['<s> the prince loves skateboarding in the park </s>', \n",
    "             '<s> the princess loves the prince but the princess hates skateboarding </s>',\n",
    "             '<s> skateboarding in the park is popular </s>',\n",
    "             '<s> the prince is popular but the prince hates attention </s>',\n",
    "             '<s> the princess loves attention but the princess hates the park </s>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should not expect to learn much with such a small sample. Furthermore, most **neural networks** perform very poorly on small datasets. However, the goal is to test if the model was implemented correctly and gain some **intuition** on how word vectors representation works. \n",
    "\n",
    "Tokens $<s>$  and $</s>$ have been added at the beginning and end of sentences respectively. This conveniently allows the context window to loop over every word **equally** (more on that later).\n",
    "\n",
    "Let's import the file and **instantiate the model** with our tiny dataset with **three nodes** in the hidden layer and learning rate of 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Word2Vec_1WordContext import Word2Vec_1WordContext\n",
    "\n",
    "model1 = Word2Vec_1WordContext(sentences, learning_rate = 1.2, nodes_HL = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is kept simple with only **three hidden nodes** because with such little data not much can be learned. In fact, we are actually better off constraining the model to **low dimensionality** in that case. In addition, three nodes will allow us to plot our word vectors on a **3D graph** and **visualize the neural network features**.\n",
    "\n",
    "The training process has been simplified to a **single iteration for every word in the text**. The function returns the learned **input weight matrix** containing the **word vectors**, and a dictionary of the **text's vocabulary** where the values are the corresponding **row indices** of the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary :\n",
      "('<s>', 0)\n",
      "('the', 1)\n",
      "('prince', 2)\n",
      "('loves', 3)\n",
      "('skateboarding', 4)\n",
      "('in', 5)\n",
      "('park', 6)\n",
      "('</s>', 7)\n",
      "('princess', 8)\n",
      "('but', 9)\n",
      "('hates', 10)\n",
      "('is', 11)\n",
      "('popular', 12)\n",
      "('attention', 13)\n",
      "\n",
      " Learned Word Vectors: \n",
      " [[ 0.15356694 -0.59457818  0.54059311]\n",
      " [ 1.57957337 -2.76142203  2.0997466 ]\n",
      " [ 0.2153512  -0.29817638  0.19946563]\n",
      " [ 0.19561163 -0.34507843  0.29477758]\n",
      " [ 0.06449394 -0.36008353  0.33284547]\n",
      " [ 0.21919323 -0.02821696  0.07743068]\n",
      " [ 0.76045179 -1.48149642  1.19209213]\n",
      " [-0.12808669  0.0439519   0.10582918]\n",
      " [ 0.2912138  -0.95082685  0.56274528]\n",
      " [ 0.26020893 -0.52035858  0.26426295]\n",
      " [ 0.34840762 -0.66855388  0.56508466]\n",
      " [ 0.13418357 -0.15368029  0.2064793 ]\n",
      " [ 0.16501661 -0.32748568  0.17810874]\n",
      " [ 0.31241319 -0.38461031  0.3336317 ]]\n"
     ]
    }
   ],
   "source": [
    "W, vocab = model1.train()\n",
    "\n",
    "print( \"Vocabulary :\")\n",
    "for kv in vocab.items():\n",
    "    print( kv)\n",
    "print( \"\\n Learned Word Vectors: \\n\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It **worked!** You maybe trust me, but you haven't gained any **intuition** on what has happened. That's the **problem** with **neural nets** they are **hard to interpret**. Fortunately, we have a very **simple model** with vectors constrained to just **three features**. Therefore, we can **visualize** them using the graphing function I incorporated in the class model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "y": [
          1,
          2,
          3
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly import graph_objs as py\n",
    "# Add your own Plotly Username and api_key\n",
    "py.sign_in('MarvinBertin', '1d708sl040')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shyamchauhan/Library/Python/3.9/lib/python/site-packages/plotly/graph_objs/_deprecations.py:378: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Line is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.scatter.Line\n",
      "  - plotly.graph_objs.layout.shape.Line\n",
      "  - etc.\n",
      "\n",
      "\n",
      "/Users/shyamchauhan/Library/Python/3.9/lib/python/site-packages/plotly/graph_objs/_deprecations.py:434: DeprecationWarning:\n",
      "\n",
      "plotly.graph_objs.Marker is deprecated.\n",
      "Please replace it with one of the following more specific types\n",
      "  - plotly.graph_objs.scatter.Marker\n",
      "  - plotly.graph_objs.histogram.selected.Marker\n",
      "  - etc.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.odict_keys' received for the 'text' property of scatter3d\n        Received value: odict_keys(['<s>', 'the', 'prince', 'loves', 'skateboarding', 'in', 'park', '</s>', 'princess', 'but', 'hates', 'is', 'popular', 'attention'])\n\n    The 'text' property is a string and must be specified as:\n      - A string\n      - A number that will be converted to a string\n      - A tuple, list, or one-dimensional numpy array of the above",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_vector_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/home/codes/Word2Vec-master/Word2Vec_1WordContext.py:99\u001b[0m, in \u001b[0;36mWord2Vec_1WordContext.graph_vector_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" 3D Scatter plot of first 3 word features with Plotly\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m vocab \u001b[38;5;241m=\u001b[39m OrderedDict(\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary\u001b[38;5;241m.\u001b[39mitems(), key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t: t[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 99\u001b[0m trace1 \u001b[38;5;241m=\u001b[39m \u001b[43mScatter3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmarkers+text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMarker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgba(217, 217, 217, 0.14)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopacity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m Data([trace1])\n\u001b[1;32m    115\u001b[0m layout \u001b[38;5;241m=\u001b[39m Layout(\n\u001b[1;32m    116\u001b[0m     margin \u001b[38;5;241m=\u001b[39m Margin(\n\u001b[1;32m    117\u001b[0m         l \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/plotly/graph_objs/_scatter3d.py:2064\u001b[0m, in \u001b[0;36mScatter3d.__init__\u001b[0;34m(self, arg, connectgaps, customdata, customdatasrc, error_x, error_y, error_z, hoverinfo, hoverinfosrc, hoverlabel, hovertemplate, hovertemplatefallback, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, legend, legendgroup, legendgrouptitle, legendrank, legendwidth, line, marker, meta, metasrc, mode, name, opacity, projection, scene, showlegend, stream, surfaceaxis, surfacecolor, text, textfont, textposition, textpositionsrc, textsrc, texttemplate, texttemplatefallback, texttemplatesrc, uid, uirevision, visible, x, xcalendar, xhoverformat, xsrc, y, ycalendar, yhoverformat, ysrc, z, zcalendar, zhoverformat, zsrc, **kwargs)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_property(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurfaceaxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, arg, surfaceaxis)\n\u001b[1;32m   2063\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_property(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, arg, surfacecolor)\n\u001b[0;32m-> 2064\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_property\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_property(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextfont\u001b[39m\u001b[38;5;124m\"\u001b[39m, arg, textfont)\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_property(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextposition\u001b[39m\u001b[38;5;124m\"\u001b[39m, arg, textposition)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/plotly/basedatatypes.py:4403\u001b[0m, in \u001b[0;36mBasePlotlyType._set_property\u001b[0;34m(self, name, arg, provided)\u001b[0m\n\u001b[1;32m   4397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_property\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, arg, provided):\n\u001b[1;32m   4398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4399\u001b[0m \u001b[38;5;124;03m    Initialize a property of this object using the provided value\u001b[39;00m\n\u001b[1;32m   4400\u001b[0m \u001b[38;5;124;03m    or a value popped from the arguments dictionary. If neither\u001b[39;00m\n\u001b[1;32m   4401\u001b[0m \u001b[38;5;124;03m    is available, do not set the property.\u001b[39;00m\n\u001b[1;32m   4402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4403\u001b[0m     \u001b[43m_set_property_provided_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovided\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/plotly/basedatatypes.py:398\u001b[0m, in \u001b[0;36m_set_property_provided_value\u001b[0;34m(obj, name, arg, provided)\u001b[0m\n\u001b[1;32m    396\u001b[0m val \u001b[38;5;241m=\u001b[39m provided \u001b[38;5;28;01mif\u001b[39;00m provided \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/plotly/basedatatypes.py:4932\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_array_prop(prop, value)\n\u001b[1;32m   4930\u001b[0m     \u001b[38;5;66;03m# ### Handle simple property ###\u001b[39;00m\n\u001b[1;32m   4931\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4932\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4933\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4934\u001b[0m     \u001b[38;5;66;03m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[1;32m   4935\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_props()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/plotly/basedatatypes.py:5276\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5274\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   5275\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   5278\u001b[0m \u001b[38;5;66;03m# val is None\u001b[39;00m\n\u001b[1;32m   5279\u001b[0m \u001b[38;5;66;03m# -----------\u001b[39;00m\n\u001b[1;32m   5280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5281\u001b[0m     \u001b[38;5;66;03m# Check if we should send null update\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/plotly/basedatatypes.py:5271\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5268\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[1;32m   5270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5271\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_coerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5272\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/_plotly_utils/basevalidators.py:1123\u001b[0m, in \u001b[0;36mStringValidator.validate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(v)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_invalid_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_blank \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_invalid_val(v)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/_plotly_utils/basevalidators.py:312\u001b[0m, in \u001b[0;36mBaseValidator.raise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m    310\u001b[0m                 name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    Invalid value of type {typ} received for the '{name}' property of {pname}\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m        Received value: {v}\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m{valid_clr_desc}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    318\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    319\u001b[0m                 pname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_name,\n\u001b[1;32m    320\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mtype_str(v),\n\u001b[1;32m    321\u001b[0m                 v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(v),\n\u001b[1;32m    322\u001b[0m                 valid_clr_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription(),\n\u001b[1;32m    323\u001b[0m             )\n\u001b[1;32m    324\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.odict_keys' received for the 'text' property of scatter3d\n        Received value: odict_keys(['<s>', 'the', 'prince', 'loves', 'skateboarding', 'in', 'park', '</s>', 'princess', 'but', 'hates', 'is', 'popular', 'attention'])\n\n    The 'text' property is a string and must be specified as:\n      - A string\n      - A number that will be converted to a string\n      - A tuple, list, or one-dimensional numpy array of the above"
     ]
    }
   ],
   "source": [
    "model1.graph_vector_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was train with very **little data** over a **small number of iterations**, therefore based on how the vectors where **initionalized** the **3D scatter plot** will **differ** a little every time you run it.\n",
    "\n",
    "Nonetheless, there is a **lot to notice** in the **representation** created by the **neural network**. Firstly, we can observe that the words are definitely **not randomly positioned**. The **word vectors** have been **moved** by the algorithm into so kind of a **structure**. \n",
    "\n",
    "For example, the tokens *\"the\"* and $</s>$ are found at both **opposite extremes** of the plot. The fact that *\"the\"* was often found at the beginning of a sentence and $</s>$ at the end, may explain this **relationship**.\n",
    "\n",
    "Furthermore, words like *\"skateboarding\"*, *\"popular\"* and *\"prince\"* are **clustered together**, whereas *\"princess\"*, *\"hates\"* and *\"but\"* form **another cluster**. From different angles, we can observe **additional structures** like *\"is popular\"* and *\"loves attention\"*.\n",
    "\n",
    "These are already pretty **impressive results**, considering how **little data** the model had. It was able to some extent capture some of the **semantics of the text**.\n",
    "\n",
    "Let's see if we can do even **better!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Word Context Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is an extention of the *Continuous Bag-Of_Word Model (CBOW)*. The context is now any **number of words**\n",
    "before the **target word** we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/2neural-network-cbow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent this **context of words**, we simply take the **average of the word vectors** in the context. The hidden layer is now the product of this **new vector** and the **input weight matrix**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h=\\frac{1}{C}W_{I}(x_1+x_2+…+x_C)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update for the output weights for the hidden-to-output layer is the same as before:\n",
    "\n",
    "$${W_{O}}^{T (new)}_j = {W_{O}}^{T (old)}_j - \\alpha \\cdot e_j \\cdot h_j$$\n",
    "\n",
    "The update for the input weights is almost identical as well. The only difference is that it now needs to be applied to **every word in the context window**.\n",
    "\n",
    "$${W_{I,c}}^{T (new)}_j = {W_{I,c}}^{T (old)}_j - \\frac{1}{C} \\cdot \\alpha \\cdot EH $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this **second model** can be found in file \"Word2Vec_nWordContext.py\"\n",
    "\n",
    "The learning algorithm is almost identical to the previous model. However, the challenge is now to find a way to allow the **context window to shrink and expand** as it loops over sentences.\n",
    "\n",
    "How do you deal with **any size context window** across **any sentence size**?\n",
    "To illustrate my point, I've created a toy function that helps to visualize how does the **context window moves across a sentence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from context_window import context_window_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "context_window_search(context_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, when the **window is small** and the **sentence long** this is straight forward. The **window slides** at every iteration. However when you have a **large window** and a **small sentence**, you will run in the problem of giving **less importance** to words at the **beginning and end** of the sentence.\n",
    "\n",
    "To get around that you need to **dynamically** change the **size of the window** as it slides across the sentence. The function below does this automatically. \n",
    "\n",
    "It **expands** gradually to the requested window size and then **contracts** as it reaches the end of the sentence. In this way, every word is passed as input excatly **5 times** for a context size of 5 for example. You can check it for yourself below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_window_search(context_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little change allows for **large improvements** in the model. The neural network can now **learning and relate** a word to both its **adjacent** and **distant neighbors**, allowing for **better semantic understanding**.\n",
    "\n",
    "Let's train this new model on our tiny dataset with this time a **context window of three words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Word2Vec_nWordContext import Word2Vec_nWordContext\n",
    "model2 = Word2Vec_nWordContext(sentences, learning_rate = 1.1, context_size = 3, nodes_HL = 3)\n",
    "W, vocab = model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2.graph_vector_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the model **pushed the word vectors** into a **structured vector space**. Some of the same previous strucutres are found here. We can also notice, if viewed the space from **different angles**, that more **subtle relationships** are starting to appear. \n",
    "\n",
    "For example, *\"princess\" - \"prince\"* **approximate** to *\"hates\" - \"loves\"*. In some sense, the model was able to capture **relations** between words that can be mapped into **mathematical operations**.\n",
    "\n",
    "To be fair, this is not completely obvious from the plot, and some of it may very well just be due to randomness in this case. However as you increase the **data size**, the **search space dimentionality** and **training time**, this model will be able to extract **deeper meaning and semantinc** from a text **efficently**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph Vector Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Paragraph Vector model is another variation of the previous models. In addition to **mapping every word** into **unique vectors**, the model will also **map the paragraphs or sentences** in the text into a **unique vector**. Each represented by a column in matrix $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/3doc2vec.png\"  width=\"500\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only real difference in the algorithm is with the **computation of the hidden layer**, $h$. Now both the **sentence vector and word vectors** are **averaged** to predict the next word in a context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h=\\frac{1}{C}W_{I}(D_d+x_1+x_2+…+x_C)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the **sentence token** as just another **vocabulary word**. However, this token vector tries to represent the **semantics of the entire sentence**. In other words, it acts as a **memory that remembers what is missing from the current context**. For this reason, this model is also referred as the ** *Distributed Memory Model of Paragraph Vectors (PV-DM)* **.\n",
    "\n",
    "As the context window travels across a sentence, the **sentence vector is unique**, whereas the **context vector changes** constantly. After being trained, the paragraph vectors can be used as **features** for the paragraph instead of **additional bag-of-words**. These features can then be used directly in other **machine learning models**, such as logistic regression or K-means.\n",
    "\n",
    "This allows the model to perform **better than a bag-of-n-grams model** because it is able to **generalize the text features** without **suffering from very high-dimensional representations** like in a bag of n-grams model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of this **third language model** was fairly straight forward, but **concenptually** the **extra paragraph token** added has the potential to greatly boost its **learning capabilities**.\n",
    "\n",
    "Let's train on our tiny dataset one last time and see the difference this model makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Doc2Vec_nWordContext import Doc2Vec_nWordContext\n",
    "model3 = Doc2Vec_nWordContext(sentences, learning_rate = 0.8, context_size = 3, nodes_HL = 3)\n",
    "W, D, vocab = model3.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training function now also returns the $D$ weight matrix, which is the **learned representation of each five sentences in the text**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3.graph_vector_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The plot of the learned word vectors, now also include the **sentence representations** (S1, S2, etc.). \n",
    "\n",
    "The first thing we can notice is that the sentence vectors have been **physically separated** from the word vectors. The model was able to **differentiate** between **individual words** and **entire sections of the text**. \n",
    "\n",
    "Furthermore, sentence vectors are grouped into a **strucutre of their own**. **S1 and S3** are together while **S2 and S4** are in another region. The first group of sentences are about **skateboarding in the park**, while the other cluster have sentences with very **similar grammatical structure**. They **compare** what the prince and princess love and hate.\n",
    "\n",
    "As discussed earlier the Paragraph Vector model takes a **general approach** and is capable of having some sort of **memory**. Therefore it can divide a text into **topics** in an **un-surpervised** way.\n",
    "\n",
    "This is **powerful** idea which allows to learn a text at **different levels or scales** (words, sentences, paragraphs). In fact, this is similar to **convolution nets** that use **max pooling** to **zoom out** of an image and learning different **feature abstractions** embedded in the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scale up to real datasets\n",
    "* Learn about NLP libraries like gensim\n",
    "* Move to more sophisticated models (hierarchical softmax, negative sampling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
